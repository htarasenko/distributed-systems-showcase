version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: distributed-systems-postgres
    environment:
      POSTGRES_DB: distributed_systems
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      # Performance optimizations
      POSTGRES_INITDB_ARGS: "--data-checksums"
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-scripts:/docker-entrypoint-initdb.d
    networks:
      - distributed-systems
    command: >
      postgres
      -c max_connections=200
      -c shared_buffers=256MB
      -c effective_cache_size=1GB
      -c maintenance_work_mem=64MB
      -c checkpoint_completion_target=0.9
      -c wal_buffers=16MB
      -c default_statistics_target=100
      -c random_page_cost=1.1
      -c effective_io_concurrency=200
      -c work_mem=4MB
      -c min_wal_size=1GB
      -c max_wal_size=4GB

  # ClickHouse Database
  clickhouse:
    image: clickhouse/clickhouse-server:latest
    container_name: distributed-systems-clickhouse
    environment:
      CLICKHOUSE_DB: distributed_systems
      CLICKHOUSE_USER: default
      CLICKHOUSE_PASSWORD: ""
      CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT: 1
    ports:
      - "8123:8123"
      - "9000:9000"
    volumes:
      - clickhouse_data:/var/lib/clickhouse
      - ./init-scripts/clickhouse-config.xml:/etc/clickhouse-server/config.d/custom.xml
      - ./init-scripts/02-init-clickhouse.sql:/docker-entrypoint-initdb.d/02-init-clickhouse.sql
    networks:
      - distributed-systems

  # Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: distributed-systems-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - distributed-systems

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: distributed-systems-kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://127.0.0.1:9092,PLAINTEXT_INTERNAL://kafka:29092,PLAINTEXT_DOCKER://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT,PLAINTEXT_DOCKER:PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_INTERNAL://0.0.0.0:29092,PLAINTEXT_DOCKER://0.0.0.0:9093
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      # Increase message size limits
      KAFKA_MESSAGE_MAX_BYTES: 10485760
      KAFKA_REPLICA_FETCH_MAX_BYTES: 10485760
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 10485760
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - distributed-systems

  # Load Balancer (Nginx)
  nginx:
    image: nginx:alpine
    container_name: distributed-systems-nginx
    ports:
      - "3000:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - app
    networks:
      - distributed-systems

  # Node.js Application (Scalable)
  app:
    build:
      context: ./src/app
      dockerfile: Dockerfile
    environment:
      - NODE_ENV=development
      - DATABASE_URL=postgresql://postgres:postgres@postgres:5432/distributed_systems
      - CLICKHOUSE_URL=http://clickhouse:8123
      - KAFKA_BROKERS=kafka:29092
      - PORT=3000
    depends_on:
      - postgres
      - clickhouse
      - kafka
    volumes:
      - ./src/app:/app
      - /app/node_modules
    networks:
      - distributed-systems
    deploy:
      replicas: 3

  # K6 Load Testing
  k6:
    build:
      context: ./src/k6
      dockerfile: Dockerfile
    container_name: distributed-systems-k6
    depends_on:
      - app
    environment:
      - APP_URL=http://app:3000
    volumes:
      - ./src/k6:/scripts
    networks:
      - distributed-systems
    profiles:
      - testing

  # Kafka UI
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: distributed-systems-kafka-ui
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
    depends_on:
      - kafka
      - zookeeper
    networks:
      - distributed-systems

  # Prometheus (Monitoring)
  prometheus:
    image: prom/prometheus:latest
    container_name: distributed-systems-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    networks:
      - distributed-systems

  # Grafana (Visualization)
  grafana:
    image: grafana/grafana:latest
    container_name: distributed-systems-grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    depends_on:
      - prometheus
    networks:
      - distributed-systems

volumes:
  postgres_data:
  clickhouse_data:
  kafka_data:
  prometheus_data:
  grafana_data:

networks:
  distributed-systems:
    driver: bridge
